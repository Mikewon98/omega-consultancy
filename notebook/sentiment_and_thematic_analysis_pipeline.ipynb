{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4e191e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Transformers not available. Install with: pip install transformers torch\n",
      "‚ö†Ô∏è Some NLP libraries not available. Install with: pip install spacy scikit-learn nltk\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLP and ML libraries\n",
    "try:\n",
    "    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "    TRANSFORMERS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TRANSFORMERS_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è Transformers not available. Install with: pip install transformers torch\")\n",
    "\n",
    "try:\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    VADER_AVAILABLE = True\n",
    "except ImportError:\n",
    "    VADER_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è VADER not available. Install with: pip install vaderSentiment\")\n",
    "\n",
    "try:\n",
    "    from textblob import TextBlob\n",
    "    TEXTBLOB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TEXTBLOB_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è TextBlob not available. Install with: pip install textblob\")\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.cluster import KMeans\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    \n",
    "    # Download required NLTK data\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    \n",
    "    NLP_LIBRARIES_AVAILABLE = True\n",
    "except ImportError:\n",
    "    NLP_LIBRARIES_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è Some NLP libraries not available. Install with: pip install spacy scikit-learn nltk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14822715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè¶ BANK REVIEWS SENTIMENT & THEMATIC ANALYSIS\n",
      "============================================================\n",
      "‚úÖ VADER sentiment analyzer loaded\n",
      "‚úÖ Loaded 3478 reviews from combined_clean_bank_reviews.csv\n",
      "Banks: Bank of Abyssinia, Commercial Bank of Ethiopia, Dashen Bank\n",
      "\n",
      "==================================================\n",
      "STARTING SENTIMENT AND THEMATIC ANALYSIS\n",
      "==================================================\n",
      "\n",
      "1. SENTIMENT ANALYSIS\n",
      "------------------------------\n",
      "Processed 50 reviews...\n",
      "Processed 100 reviews...\n",
      "Processed 150 reviews...\n",
      "Processed 200 reviews...\n",
      "Processed 250 reviews...\n",
      "Processed 300 reviews...\n",
      "Processed 350 reviews...\n",
      "Processed 400 reviews...\n",
      "Processed 450 reviews...\n",
      "Processed 500 reviews...\n",
      "Processed 550 reviews...\n",
      "Processed 600 reviews...\n",
      "Processed 650 reviews...\n",
      "Processed 700 reviews...\n",
      "Processed 750 reviews...\n",
      "Processed 800 reviews...\n",
      "Processed 850 reviews...\n",
      "Processed 900 reviews...\n",
      "Processed 950 reviews...\n",
      "Processed 1000 reviews...\n",
      "Processed 1050 reviews...\n",
      "Processed 1100 reviews...\n",
      "Processed 1150 reviews...\n",
      "Processed 1200 reviews...\n",
      "Processed 1250 reviews...\n",
      "Processed 1300 reviews...\n",
      "Processed 1350 reviews...\n",
      "Processed 1400 reviews...\n",
      "Processed 1450 reviews...\n",
      "Processed 1500 reviews...\n",
      "Processed 1550 reviews...\n",
      "Processed 1600 reviews...\n",
      "Processed 1650 reviews...\n",
      "Processed 1700 reviews...\n",
      "Processed 1750 reviews...\n",
      "Processed 1800 reviews...\n",
      "Processed 1850 reviews...\n",
      "Processed 1900 reviews...\n",
      "Processed 1950 reviews...\n",
      "Processed 2000 reviews...\n",
      "Processed 2050 reviews...\n",
      "Processed 2100 reviews...\n",
      "Processed 2150 reviews...\n",
      "Processed 2200 reviews...\n",
      "Processed 2250 reviews...\n",
      "Processed 2300 reviews...\n",
      "Processed 2350 reviews...\n",
      "Processed 2400 reviews...\n",
      "Processed 2450 reviews...\n",
      "Processed 2500 reviews...\n",
      "Processed 2550 reviews...\n",
      "Processed 2600 reviews...\n",
      "Processed 2650 reviews...\n",
      "Processed 2700 reviews...\n",
      "Processed 2750 reviews...\n",
      "Processed 2800 reviews...\n",
      "Processed 2850 reviews...\n",
      "Processed 2900 reviews...\n",
      "Processed 2950 reviews...\n",
      "Processed 3000 reviews...\n",
      "Processed 3050 reviews...\n",
      "Processed 3100 reviews...\n",
      "Processed 3150 reviews...\n",
      "Processed 3200 reviews...\n",
      "Processed 3250 reviews...\n",
      "Processed 3300 reviews...\n",
      "Processed 3350 reviews...\n",
      "Processed 3400 reviews...\n",
      "Processed 3450 reviews...\n",
      "‚úÖ Sentiment analysis completed for 3478 reviews\n",
      "\n",
      "2. THEMATIC ANALYSIS\n",
      "------------------------------\n",
      "\n",
      "Analyzing themes for Bank of Abyssinia...\n",
      "TF-IDF error: name 'TfidfVectorizer' is not defined\n",
      "  Top themes: []\n",
      "\n",
      "Analyzing themes for Commercial Bank of Ethiopia...\n",
      "TF-IDF error: name 'TfidfVectorizer' is not defined\n",
      "  Top themes: []\n",
      "\n",
      "Analyzing themes for Dashen Bank...\n",
      "TF-IDF error: name 'TfidfVectorizer' is not defined\n",
      "  Top themes: []\n",
      "\n",
      "==================================================\n",
      "ANALYSIS SUMMARY REPORT\n",
      "==================================================\n",
      "\n",
      "1. SENTIMENT ANALYSIS SUMMARY\n",
      "------------------------------\n",
      "Overall Sentiment Distribution (VADER):\n",
      "  POSITIVE: 1764 (50.7%)\n",
      "  NEUTRAL: 1163 (33.4%)\n",
      "  NEGATIVE: 550 (15.8%)\n",
      "\n",
      "Sentiment by Bank:\n",
      "  Bank of Abyssinia: Pos: 340(38.2%) Neg: 246(27.7%) Neu: 302(34.0%)\n",
      "  Commercial Bank of Ethiopia: Pos: 1130(51.8%) Neg: 278(12.8%) Neu: 772(35.4%)\n",
      "  Dashen Bank: Pos: 294(71.9%) Neg: 26(6.4%) Neu: 89(21.8%)\n",
      "\n",
      "Sentiment by Rating:\n",
      "vader_sentiment  NEGATIVE  NEUTRAL  POSITIVE\n",
      "rating                                      \n",
      "1                     184      294       355\n",
      "2                      31       65        86\n",
      "3                      28       69        97\n",
      "4                      27       84       138\n",
      "5                     280      651      1088\n",
      "\n",
      "2. THEMATIC ANALYSIS SUMMARY\n",
      "------------------------------\n",
      "\n",
      "Bank of Abyssinia:\n",
      "  Top Themes:\n",
      "  Top Keywords:\n",
      "\n",
      "Commercial Bank of Ethiopia:\n",
      "  Top Themes:\n",
      "  Top Keywords:\n",
      "\n",
      "Dashen Bank:\n",
      "  Top Themes:\n",
      "  Top Keywords:\n",
      "\n",
      "Overall Theme Distribution:\n",
      "  General: 3478 (100.0%)\n",
      "\n",
      "‚úÖ Analysis results saved to: bank_reviews_analysis_results.csv\n",
      "   Total reviews analyzed: 3478\n",
      "   Columns included: review_id, review, rating, date, source, bank, vader_sentiment, vader_score, textblob_sentiment, textblob_score, identified_themes\n",
      "\n",
      "üéâ Analysis completed successfully!\n",
      "üìä Results saved to: bank_reviews_analysis_results.csv\n",
      "üìà Ready for CX insights and recommendations!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class BankReviewAnalyzer:\n",
    "    def __init__(self, data_path='combined_clean_bank_reviews.csv'):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with cleaned review data\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.df = None\n",
    "        self.results_df = None\n",
    "        \n",
    "        # Initialize sentiment analyzers if available\n",
    "        self.distilbert_analyzer = None\n",
    "        self.vader_analyzer = None\n",
    "        \n",
    "        # Initialize NLP components\n",
    "        self.stopwords = set()\n",
    "        self.lemmatizer = None\n",
    "        \n",
    "        self._setup_analyzers()\n",
    "        \n",
    "    def _setup_analyzers(self):\n",
    "        \"\"\"Setup sentiment analyzers and NLP components\"\"\"\n",
    "        \n",
    "        # Setup DistilBERT\n",
    "        if TRANSFORMERS_AVAILABLE:\n",
    "            try:\n",
    "                self.distilbert_analyzer = pipeline(\n",
    "                    \"sentiment-analysis\",\n",
    "                    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "                    return_all_scores=True\n",
    "                )\n",
    "                print(\"‚úÖ DistilBERT sentiment analyzer loaded\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è DistilBERT loading failed: {e}\")\n",
    "        \n",
    "        # Setup VADER\n",
    "        if VADER_AVAILABLE:\n",
    "            self.vader_analyzer = SentimentIntensityAnalyzer()\n",
    "            print(\"‚úÖ VADER sentiment analyzer loaded\")\n",
    "        \n",
    "        # Setup NLP components\n",
    "        if NLP_LIBRARIES_AVAILABLE:\n",
    "            try:\n",
    "                self.stopwords = set(stopwords.words('english'))\n",
    "                self.lemmatizer = WordNetLemmatizer()\n",
    "                print(\"‚úÖ NLP components loaded\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Load the cleaned review data\"\"\"\n",
    "        try:\n",
    "            self.df = pd.read_csv('../data/.combined_clean_bank_reviews.csv')\n",
    "            print(f\"‚úÖ Loaded {len(self.df)} reviews from {self.data_path}\")\n",
    "            print(f\"Banks: {', '.join(self.df['bank'].unique())}\")\n",
    "            return True\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå File {self.data_path} not found. Please run data cleaning first.\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading data: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def analyze_sentiment_distilbert(self, text):\n",
    "        \"\"\"Analyze sentiment using DistilBERT\"\"\"\n",
    "        if not self.distilbert_analyzer:\n",
    "            return None, None, None\n",
    "        \n",
    "        try:\n",
    "            results = self.distilbert_analyzer(text[:512])  # Truncate for model limits\n",
    "            \n",
    "            # Extract scores\n",
    "            positive_score = next((item['score'] for item in results[0] if item['label'] == 'POSITIVE'), 0)\n",
    "            negative_score = next((item['score'] for item in results[0] if item['label'] == 'NEGATIVE'), 0)\n",
    "            \n",
    "            # Determine dominant sentiment\n",
    "            if positive_score > negative_score:\n",
    "                sentiment_label = 'POSITIVE'\n",
    "                confidence = positive_score\n",
    "            else:\n",
    "                sentiment_label = 'NEGATIVE' \n",
    "                confidence = negative_score\n",
    "            \n",
    "            return sentiment_label, confidence, {'positive': positive_score, 'negative': negative_score}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"DistilBERT error: {e}\")\n",
    "            return None, None, None\n",
    "    \n",
    "    def analyze_sentiment_vader(self, text):\n",
    "        \"\"\"Analyze sentiment using VADER\"\"\"\n",
    "        if not self.vader_analyzer:\n",
    "            return None, None, None\n",
    "        \n",
    "        try:\n",
    "            scores = self.vader_analyzer.polarity_scores(text)\n",
    "            \n",
    "            # Determine sentiment label\n",
    "            if scores['compound'] >= 0.05:\n",
    "                sentiment_label = 'POSITIVE'\n",
    "            elif scores['compound'] <= -0.05:\n",
    "                sentiment_label = 'NEGATIVE'\n",
    "            else:\n",
    "                sentiment_label = 'NEUTRAL'\n",
    "            \n",
    "            return sentiment_label, abs(scores['compound']), scores\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"VADER error: {e}\")\n",
    "            return None, None, None\n",
    "    \n",
    "    def analyze_sentiment_textblob(self, text):\n",
    "        \"\"\"Analyze sentiment using TextBlob\"\"\"\n",
    "        if not TEXTBLOB_AVAILABLE:\n",
    "            return None, None, None\n",
    "        \n",
    "        try:\n",
    "            blob = TextBlob(text)\n",
    "            polarity = blob.sentiment.polarity\n",
    "            \n",
    "            if polarity > 0.1:\n",
    "                sentiment_label = 'POSITIVE'\n",
    "            elif polarity < -0.1:\n",
    "                sentiment_label = 'NEGATIVE'\n",
    "            else:\n",
    "                sentiment_label = 'NEUTRAL'\n",
    "            \n",
    "            return sentiment_label, abs(polarity), {'polarity': polarity, 'subjectivity': blob.sentiment.subjectivity}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"TextBlob error: {e}\")\n",
    "            return None, None, None\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Preprocess text for thematic analysis\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        if NLP_LIBRARIES_AVAILABLE:\n",
    "            try:\n",
    "                tokens = word_tokenize(text)\n",
    "                # Remove stopwords and lemmatize\n",
    "                tokens = [self.lemmatizer.lemmatize(token) for token in tokens \n",
    "                         if token not in self.stopwords and len(token) > 2]\n",
    "                return ' '.join(tokens)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Fallback preprocessing\n",
    "        words = text.split()\n",
    "        words = [word for word in words if len(word) > 2]\n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def extract_keywords_tfidf(self, texts, max_features=100):\n",
    "        \"\"\"Extract keywords using TF-IDF\"\"\"\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer(\n",
    "                max_features=max_features,\n",
    "                ngram_range=(1, 2),\n",
    "                min_df=2,\n",
    "                max_df=0.8\n",
    "            )\n",
    "            \n",
    "            tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "            \n",
    "            # Get average TF-IDF scores\n",
    "            mean_scores = np.array(tfidf_matrix.mean(axis=0)).flatten()\n",
    "            \n",
    "            # Create keyword-score pairs\n",
    "            keyword_scores = list(zip(feature_names, mean_scores))\n",
    "            keyword_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            return keyword_scores\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"TF-IDF error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def identify_themes(self, keywords, bank_name):\n",
    "        \"\"\"Rule-based theme identification from keywords\"\"\"\n",
    "        \n",
    "        # Define theme patterns\n",
    "        theme_patterns = {\n",
    "            'Account Access Issues': [\n",
    "                'login', 'password', 'access', 'crash', 'error', 'bug', 'not working',\n",
    "                'cant login', 'login problem', 'authentication', 'account lock'\n",
    "            ],\n",
    "            'Transaction Performance': [\n",
    "                'transfer', 'payment', 'transaction', 'slow', 'fast', 'quick',\n",
    "                'money transfer', 'send money', 'balance', 'deposit', 'withdraw'\n",
    "            ],\n",
    "            'User Interface & Experience': [\n",
    "                'app', 'interface', 'design', 'easy', 'simple', 'navigation',\n",
    "                'user friendly', 'ui', 'layout', 'menu', 'screen'\n",
    "            ],\n",
    "            'Customer Support': [\n",
    "                'support', 'help', 'service', 'staff', 'customer', 'response',\n",
    "                'assistance', 'call center', 'feedback'\n",
    "            ],\n",
    "            'Feature Requests': [\n",
    "                'need', 'want', 'should', 'feature', 'update', 'improvement',\n",
    "                'add', 'missing', 'wish', 'hope'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Score themes based on keyword matches\n",
    "        theme_scores = {theme: 0 for theme in theme_patterns}\n",
    "        \n",
    "        for keyword, score in keywords[:50]:  # Top 50 keywords\n",
    "            keyword_lower = keyword.lower()\n",
    "            for theme, patterns in theme_patterns.items():\n",
    "                for pattern in patterns:\n",
    "                    if pattern in keyword_lower:\n",
    "                        theme_scores[theme] += score\n",
    "        \n",
    "        # Get top themes\n",
    "        sorted_themes = sorted(theme_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_themes = [(theme, score) for theme, score in sorted_themes if score > 0]\n",
    "        \n",
    "        return top_themes[:5]  # Return top 5 themes\n",
    "    \n",
    "    def analyze_reviews(self):\n",
    "        \"\"\"Main analysis pipeline\"\"\"\n",
    "        if not self.load_data():\n",
    "            return False\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"STARTING SENTIMENT AND THEMATIC ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Initialize results dataframe\n",
    "        self.results_df = self.df.copy()\n",
    "        \n",
    "        # Add review ID\n",
    "        self.results_df['review_id'] = range(1, len(self.results_df) + 1)\n",
    "        \n",
    "        # Sentiment analysis\n",
    "        print(\"\\n1. SENTIMENT ANALYSIS\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        sentiment_results = []\n",
    "        \n",
    "        for idx, row in self.df.iterrows():\n",
    "            review_text = str(row['review'])\n",
    "            result = {'review_id': idx + 1}\n",
    "            \n",
    "            # DistilBERT analysis\n",
    "            if self.distilbert_analyzer:\n",
    "                label, score, details = self.analyze_sentiment_distilbert(review_text)\n",
    "                result['distilbert_sentiment'] = label\n",
    "                result['distilbert_score'] = score\n",
    "            \n",
    "            # VADER analysis\n",
    "            if self.vader_analyzer:\n",
    "                label, score, details = self.analyze_sentiment_vader(review_text)\n",
    "                result['vader_sentiment'] = label\n",
    "                result['vader_score'] = score\n",
    "            \n",
    "            # TextBlob analysis\n",
    "            label, score, details = self.analyze_sentiment_textblob(review_text)\n",
    "            result['textblob_sentiment'] = label\n",
    "            result['textblob_score'] = score\n",
    "            \n",
    "            sentiment_results.append(result)\n",
    "            \n",
    "            if (idx + 1) % 50 == 0:\n",
    "                print(f\"Processed {idx + 1} reviews...\")\n",
    "        \n",
    "        # Add sentiment results to dataframe\n",
    "        sentiment_df = pd.DataFrame(sentiment_results)\n",
    "        self.results_df = self.results_df.merge(sentiment_df, left_index=True, right_on='review_id', how='left')\n",
    "        \n",
    "        print(f\"‚úÖ Sentiment analysis completed for {len(self.results_df)} reviews\")\n",
    "        \n",
    "        # Thematic analysis by bank\n",
    "        print(f\"\\n2. THEMATIC ANALYSIS\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        bank_themes = {}\n",
    "        \n",
    "        for bank in self.df['bank'].unique():\n",
    "            print(f\"\\nAnalyzing themes for {bank}...\")\n",
    "            \n",
    "            bank_reviews = self.df[self.df['bank'] == bank]['review'].tolist()\n",
    "            \n",
    "            # Preprocess reviews\n",
    "            processed_reviews = [self.preprocess_text(review) for review in bank_reviews]\n",
    "            processed_reviews = [text for text in processed_reviews if text.strip()]\n",
    "            \n",
    "            if processed_reviews:\n",
    "                # Extract keywords\n",
    "                keywords = self.extract_keywords_tfidf(processed_reviews)\n",
    "                \n",
    "                # Identify themes\n",
    "                themes = self.identify_themes(keywords, bank)\n",
    "                \n",
    "                bank_themes[bank] = {\n",
    "                    'keywords': keywords[:20],  # Top 20 keywords\n",
    "                    'themes': themes\n",
    "                }\n",
    "                \n",
    "                print(f\"  Top themes: {[theme for theme, score in themes[:3]]}\")\n",
    "        \n",
    "        # Add theme information to results\n",
    "        theme_mapping = []\n",
    "        for _, row in self.results_df.iterrows():\n",
    "            bank = row['bank']\n",
    "            review_text = str(row['review']).lower()\n",
    "            \n",
    "            identified_themes = []\n",
    "            if bank in bank_themes:\n",
    "                for theme, score in bank_themes[bank]['themes']:\n",
    "                    # Simple rule-based theme assignment\n",
    "                    theme_patterns = {\n",
    "                        'Account Access Issues': ['login', 'password', 'crash', 'error', 'bug'],\n",
    "                        'Transaction Performance': ['transfer', 'payment', 'slow', 'fast'],\n",
    "                        'User Interface & Experience': ['app', 'interface', 'easy', 'simple'],\n",
    "                        'Customer Support': ['support', 'help', 'service'],\n",
    "                        'Feature Requests': ['need', 'want', 'feature', 'update']\n",
    "                    }\n",
    "                    \n",
    "                    if theme in theme_patterns:\n",
    "                        for pattern in theme_patterns[theme]:\n",
    "                            if pattern in review_text:\n",
    "                                identified_themes.append(theme)\n",
    "                                break\n",
    "            \n",
    "            theme_mapping.append({\n",
    "                'review_id': row['review_id'],\n",
    "                'identified_themes': '; '.join(identified_themes[:2]) if identified_themes else 'General'\n",
    "            })\n",
    "        \n",
    "        theme_df = pd.DataFrame(theme_mapping)\n",
    "        self.results_df = self.results_df.merge(theme_df, on='review_id', how='left')\n",
    "        \n",
    "        # Generate summary statistics\n",
    "        self.generate_summary_report(bank_themes)\n",
    "        \n",
    "        # Save results\n",
    "        self.save_results()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def generate_summary_report(self, bank_themes):\n",
    "        \"\"\"Generate comprehensive analysis report\"\"\"\n",
    "        print(f\"\\n\" + \"=\"*50)\n",
    "        print(\"ANALYSIS SUMMARY REPORT\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Sentiment summary\n",
    "        print(f\"\\n1. SENTIMENT ANALYSIS SUMMARY\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Overall sentiment distribution\n",
    "        if 'vader_sentiment' in self.results_df.columns:\n",
    "            sentiment_dist = self.results_df['vader_sentiment'].value_counts()\n",
    "            print(f\"Overall Sentiment Distribution (VADER):\")\n",
    "            for sentiment, count in sentiment_dist.items():\n",
    "                percentage = (count / len(self.results_df)) * 100\n",
    "                print(f\"  {sentiment}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Sentiment by bank\n",
    "        print(f\"\\nSentiment by Bank:\")\n",
    "        for bank in self.results_df['bank'].unique():\n",
    "            bank_data = self.results_df[self.results_df['bank'] == bank]\n",
    "            if 'vader_sentiment' in bank_data.columns:\n",
    "                pos_count = (bank_data['vader_sentiment'] == 'POSITIVE').sum()\n",
    "                neg_count = (bank_data['vader_sentiment'] == 'NEGATIVE').sum()\n",
    "                neu_count = (bank_data['vader_sentiment'] == 'NEUTRAL').sum()\n",
    "                total = len(bank_data)\n",
    "                \n",
    "                print(f\"  {bank}: Pos: {pos_count}({pos_count/total*100:.1f}%) \"\n",
    "                      f\"Neg: {neg_count}({neg_count/total*100:.1f}%) \"\n",
    "                      f\"Neu: {neu_count}({neu_count/total*100:.1f}%)\")\n",
    "        \n",
    "        # Sentiment by rating\n",
    "        print(f\"\\nSentiment by Rating:\")\n",
    "        if 'vader_sentiment' in self.results_df.columns:\n",
    "            sentiment_rating = self.results_df.groupby(['rating', 'vader_sentiment']).size().unstack(fill_value=0)\n",
    "            print(sentiment_rating)\n",
    "        \n",
    "        # Thematic analysis summary\n",
    "        print(f\"\\n2. THEMATIC ANALYSIS SUMMARY\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for bank, analysis in bank_themes.items():\n",
    "            print(f\"\\n{bank}:\")\n",
    "            print(f\"  Top Themes:\")\n",
    "            for i, (theme, score) in enumerate(analysis['themes'][:3], 1):\n",
    "                print(f\"    {i}. {theme} (score: {score:.3f})\")\n",
    "            \n",
    "            print(f\"  Top Keywords:\")\n",
    "            for i, (keyword, score) in enumerate(analysis['keywords'][:5], 1):\n",
    "                print(f\"    {i}. {keyword} ({score:.3f})\")\n",
    "        \n",
    "        # Theme distribution\n",
    "        if 'identified_themes' in self.results_df.columns:\n",
    "            theme_dist = self.results_df['identified_themes'].value_counts()\n",
    "            print(f\"\\nOverall Theme Distribution:\")\n",
    "            for theme, count in theme_dist.head(10).items():\n",
    "                percentage = (count / len(self.results_df)) * 100\n",
    "                print(f\"  {theme}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    def save_results(self):\n",
    "        \"\"\"Save analysis results to CSV\"\"\"\n",
    "        \n",
    "        # Select final columns for output\n",
    "        output_columns = [\n",
    "            'review_id', 'review', 'rating', 'date', 'source', 'bank'\n",
    "        ]\n",
    "        \n",
    "        # Add available sentiment columns\n",
    "        sentiment_columns = ['distilbert_sentiment', 'distilbert_score', \n",
    "                           'vader_sentiment', 'vader_score', \n",
    "                           'textblob_sentiment', 'textblob_score']\n",
    "        \n",
    "        for col in sentiment_columns:\n",
    "            if col in self.results_df.columns:\n",
    "                output_columns.append(col)\n",
    "        \n",
    "        # Add theme column\n",
    "        if 'identified_themes' in self.results_df.columns:\n",
    "            output_columns.append('identified_themes')\n",
    "        \n",
    "        # Create final output dataframe\n",
    "        output_df = self.results_df[output_columns].copy()\n",
    "        \n",
    "        # Save to CSV\n",
    "        output_filename = 'bank_reviews_analysis_results.csv'\n",
    "        output_df.to_csv(f'../data/{output_filename}', index=False)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Analysis results saved to: {output_filename}\")\n",
    "        print(f\"   Total reviews analyzed: {len(output_df)}\")\n",
    "        print(f\"   Columns included: {', '.join(output_columns)}\")\n",
    "        \n",
    "        return output_filename\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print(\"üè¶ BANK REVIEWS SENTIMENT & THEMATIC ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = BankReviewAnalyzer()\n",
    "    \n",
    "    # Run analysis\n",
    "    success = analyzer.analyze_reviews()\n",
    "    \n",
    "    if success:\n",
    "        print(f\"\\nüéâ Analysis completed successfully!\")\n",
    "        print(f\"üìä Results saved to: bank_reviews_analysis_results.csv\")\n",
    "        print(f\"üìà Ready for CX insights and recommendations!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Analysis failed. Please check data and dependencies.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
